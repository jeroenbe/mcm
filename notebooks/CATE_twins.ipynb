{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc95eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import sys, os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from econml.dml import NonParamDML, LinearDML\n",
    "from econml.dr import LinearDRLearner, ForestDRLearner\n",
    "from econml.metalearners import XLearner\n",
    "from econml import metalearners\n",
    "\n",
    "import sklearn\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.svm import SVC, SVR\n",
    "\n",
    "from src.data.data_module import (\n",
    "    generate_data_exp,\n",
    "    _generate_covariates,\n",
    "    _get_twins_data_covariates,\n",
    ")\n",
    "from src.data.utils import split_eval_cate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6809b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regressor(missing_value):\n",
    "    return XGBRegressor(missing=missing_value, eval_metric=\"logloss\")\n",
    "\n",
    "\n",
    "def get_classifier(missing_value):\n",
    "    return XGBClassifier(\n",
    "        use_label_encoder=False, missing=missing_value, eval_metric=\"logloss\"\n",
    "    )\n",
    "\n",
    "\n",
    "def get_imputer(missing_value):\n",
    "    return IterativeImputer(\n",
    "        max_iter=1500, tol=15e-4, random_state=None, missing_values=missing_value\n",
    "    )\n",
    "    # return SimpleImputer(missing_values=0, strategy='mean')\n",
    "\n",
    "\n",
    "learners = {\n",
    "    \"T\": lambda missing_value: metalearners.TLearner(\n",
    "        models=get_regressor(missing_value)\n",
    "    ),\n",
    "    \"X\": lambda missing_value: XLearner(\n",
    "        models=get_regressor(missing_value),\n",
    "        propensity_model=get_classifier(missing_value),\n",
    "        cate_models=get_regressor(missing_value),\n",
    "    ),\n",
    "    \"DR\": lambda missing_value: ForestDRLearner(\n",
    "        model_propensity=get_classifier(missing_value),\n",
    "        model_regression=get_regressor(missing_value),\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "def evaluate(ground_truth, estimate, W):\n",
    "    PEHE = np.sqrt(((estimate - ground_truth) ** 2).mean())\n",
    "    PEHE_0 = np.sqrt(((estimate[W == 0] - ground_truth[W == 0]) ** 2).mean())\n",
    "    PEHE_1 = np.sqrt(((estimate[W == 1] - ground_truth[W == 1]) ** 2).mean())\n",
    "    return PEHE, PEHE_0, PEHE_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9ad448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP. SETTINGS\n",
    "runs = 100\n",
    "sims = 10\n",
    "\n",
    "data = \"twins\"\n",
    "\n",
    "assert runs % sims == 0\n",
    "\n",
    "\n",
    "train_size = 5000\n",
    "\n",
    "d = 48  # twins\n",
    "z_d_dim = 24\n",
    "amount_of_missingness = 0.1\n",
    "missing_value = -1\n",
    "\n",
    "learner = \"X\"\n",
    "\n",
    "\n",
    "# DEBUG SETTINGS\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5378f732",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_cate = []\n",
    "ground_truth_cate_0 = []\n",
    "ground_truth_cate_1 = []\n",
    "\n",
    "\n",
    "PEHE_impute_all = []\n",
    "PEHE_impute_nothing = []\n",
    "PEHE_impute_smartly = []\n",
    "PEHE_impute_wrongly = []\n",
    "\n",
    "effect_impute_all = []\n",
    "effect_impute_nothing = []\n",
    "effect_impute_smartly = []\n",
    "effect_impute_wrongly = []\n",
    "\n",
    "effect_impute_all_0 = []\n",
    "effect_impute_nothing_0 = []\n",
    "effect_impute_smartly_0 = []\n",
    "effect_impute_wrongly_0 = []\n",
    "\n",
    "effect_impute_all_1 = []\n",
    "effect_impute_nothing_1 = []\n",
    "effect_impute_smartly_1 = []\n",
    "effect_impute_wrongly_1 = []\n",
    "for _ in tqdm(range(sims)):\n",
    "    X, X_, Y0, Y1, Y, CATE, W, Z_up, Z_down = generate_data_exp(\n",
    "        train_size * 2,\n",
    "        d,\n",
    "        z_d_dim,\n",
    "        amount_of_missingness,\n",
    "        missing_value=missing_value,\n",
    "        data=data,\n",
    "    )\n",
    "\n",
    "    assert 10 < train_size < len(X)\n",
    "\n",
    "    for _ in tqdm(range(int(runs / sims)), leave=False):\n",
    "        idxs = np.random.choice(range(len(X)), size=train_size, replace=False)\n",
    "        include_idx = set(idxs)\n",
    "        mask = np.array([(i in include_idx) for i in range(len(X))])\n",
    "\n",
    "        X_train, Y_train, W_train, CATE_train = X_[mask], Y[mask], W[mask], CATE[mask]\n",
    "        X_test, Y_test, W_test, CATE_test = X_[~mask], Y[~mask], W[~mask], CATE[~mask]\n",
    "\n",
    "        ground_truth_cate.append(CATE_test)\n",
    "        ground_truth_cate_0.append(CATE_test[W_test == 0])\n",
    "        ground_truth_cate_1.append(CATE_test[W_test == 1])\n",
    "\n",
    "        # IMPUTE ALL\n",
    "        imputer = get_imputer(missing_value)\n",
    "        imputer.fit(X_train)\n",
    "        X_train_preprocessed = imputer.transform(X_train)\n",
    "        X_test_preprocessed = imputer.transform(X_test)\n",
    "\n",
    "        est_impute_all = learners[learner](missing_value)\n",
    "        est_impute_all.fit(Y_train, W_train, X=X_train_preprocessed)\n",
    "\n",
    "        # PEHE_impute_all.append(evaluate(CATE_test, te, W_test))\n",
    "        effect_impute_all.append(est_impute_all.effect(X_test_preprocessed))\n",
    "        effect_impute_all_0.append(\n",
    "            est_impute_all.effect(X_test_preprocessed[W_test == 0])\n",
    "        )\n",
    "        effect_impute_all_1.append(\n",
    "            est_impute_all.effect(X_test_preprocessed[W_test == 1])\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print(\"all\", X_train.min())\n",
    "\n",
    "        # IMPUTE NOTHING\n",
    "        treatment_effects_impute_nothing = []\n",
    "        X_train_preprocessed = X_train.copy()\n",
    "        X_test_preprocessed = X_test.copy()\n",
    "\n",
    "        est_impute_nothing = learners[learner](missing_value)\n",
    "        est_impute_nothing.fit(Y_train, W_train, X=X_train_preprocessed)\n",
    "\n",
    "        # PEHE_impute_nothing.append(evaluate(CATE_test, te, W_test))\n",
    "        effect_impute_nothing.append(est_impute_nothing.effect(X_test_preprocessed))\n",
    "        effect_impute_nothing_0.append(\n",
    "            est_impute_nothing.effect(X_test_preprocessed[W_test == 0])\n",
    "        )\n",
    "        effect_impute_nothing_1.append(\n",
    "            est_impute_nothing.effect(X_test_preprocessed[W_test == 1])\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print(\"nothing\", X_train.min())\n",
    "\n",
    "        # IMPUTE SMARTLY\n",
    "        treatment_effects_impute_smartly = []\n",
    "        imputer_smart = get_imputer(missing_value)\n",
    "        imputer_smart.fit(X_train[:, z_d_dim:])\n",
    "\n",
    "        X_train_preprocessed = X_train.copy()\n",
    "        X_test_preprocessed = X_test.copy()\n",
    "\n",
    "        X_train_preprocessed[:, z_d_dim:] = imputer_smart.transform(\n",
    "            X_train[:, z_d_dim:]\n",
    "        )\n",
    "        X_test_preprocessed[:, z_d_dim:] = imputer_smart.transform(X_test[:, z_d_dim:])\n",
    "\n",
    "        est_impute_smartly = learners[learner](missing_value)\n",
    "        est_impute_smartly.fit(Y_train, W_train, X=X_train_preprocessed)\n",
    "\n",
    "        # PEHE_impute_smartly.append(evaluate(CATE_test, te, W_test))\n",
    "        effect_impute_smartly.append(est_impute_smartly.effect(X_test_preprocessed))\n",
    "        effect_impute_smartly_0.append(\n",
    "            est_impute_smartly.effect(X_test_preprocessed[W_test == 0])\n",
    "        )\n",
    "        effect_impute_smartly_1.append(\n",
    "            est_impute_smartly.effect(X_test_preprocessed[W_test == 1])\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print(\"smart down\", X_train[:, :z_d_dim].min())\n",
    "            print(\"smart up\", X_train[:, z_d_dim:].min())\n",
    "\n",
    "        # IMPUTE WRONGLY\n",
    "        treatment_effects_impute_wrongly = []\n",
    "        imputer_wrongly = get_imputer(missing_value)\n",
    "        imputer_wrongly.fit(X_train[:, :z_d_dim])\n",
    "\n",
    "        X_train_preprocessed = X_train.copy()\n",
    "        X_test_preprocessed = X_test.copy()\n",
    "\n",
    "        X_train_preprocessed[:, :z_d_dim] = imputer_wrongly.transform(\n",
    "            X_train[:, :z_d_dim]\n",
    "        )\n",
    "        X_test_preprocessed[:, :z_d_dim] = imputer_wrongly.transform(\n",
    "            X_test[:, :z_d_dim]\n",
    "        )\n",
    "\n",
    "        est_impute_wrongly = learners[learner](missing_value)\n",
    "        est_impute_wrongly.fit(Y_train, W_train, X=X_train_preprocessed)\n",
    "\n",
    "        # PEHE_impute_wrongly.append(evaluate(CATE_test, te, W_test))\n",
    "        effect_impute_wrongly.append(est_impute_wrongly.effect(X_test_preprocessed))\n",
    "        effect_impute_wrongly_0.append(\n",
    "            est_impute_wrongly.effect(X_test_preprocessed[W_test == 0])\n",
    "        )\n",
    "        effect_impute_wrongly_1.append(\n",
    "            est_impute_wrongly.effect(X_test_preprocessed[W_test == 1])\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print(\"wrong down\", X_train[:, :z_d_dim].min())\n",
    "            print(\"wrong up\", X_train[:, z_d_dim:].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2331df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_means, all_stds = split_eval_cate(effect_impute_all, ground_truth_cate, sims)\n",
    "no_means, no_stds = split_eval_cate(effect_impute_nothing, ground_truth_cate, sims)\n",
    "smart_means, smart_stds = split_eval_cate(\n",
    "    effect_impute_smartly, ground_truth_cate, sims\n",
    ")\n",
    "wrong_means, wrong_stds = split_eval_cate(\n",
    "    effect_impute_wrongly, ground_truth_cate, sims\n",
    ")\n",
    "\n",
    "all_means_0, all_stds_0 = split_eval_cate(\n",
    "    effect_impute_all_0, ground_truth_cate_0, sims\n",
    ")\n",
    "no_means_0, no_stds_0 = split_eval_cate(\n",
    "    effect_impute_nothing_0, ground_truth_cate_0, sims\n",
    ")\n",
    "smart_means_0, smart_stds_0 = split_eval_cate(\n",
    "    effect_impute_smartly_0, ground_truth_cate_0, sims\n",
    ")\n",
    "wrong_means_0, wrong_stds_0 = split_eval_cate(\n",
    "    effect_impute_wrongly_0, ground_truth_cate_0, sims\n",
    ")\n",
    "\n",
    "all_means_1, all_stds_1 = split_eval_cate(\n",
    "    effect_impute_all_1, ground_truth_cate_1, sims\n",
    ")\n",
    "no_means_1, no_stds_1 = split_eval_cate(\n",
    "    effect_impute_nothing_1, ground_truth_cate_1, sims\n",
    ")\n",
    "smart_means_1, smart_stds_1 = split_eval_cate(\n",
    "    effect_impute_smartly_1, ground_truth_cate_1, sims\n",
    ")\n",
    "wrong_means_1, wrong_stds_1 = split_eval_cate(\n",
    "    effect_impute_wrongly_1, ground_truth_cate_1, sims\n",
    ")\n",
    "\n",
    "const = np.append(all_means, [no_means, smart_means, wrong_means]).max()\n",
    "const_0 = np.append(all_means_0, [no_means_0, smart_means_0, wrong_means_0]).max()\n",
    "const_1 = np.append(all_means_1, [no_means_1, smart_means_1, wrong_means_1]).max()\n",
    "\n",
    "print(\"# SETUP\")\n",
    "print(f\"# DATA = {data}\")\n",
    "print(f\"# learner = {learner}\")\n",
    "print(f\"# amount_of_missingness = {amount_of_missingness}\")\n",
    "print(f\"# z_d_dim = {z_d_dim}\")\n",
    "print(f\"# train size = {train_size}\")\n",
    "print(f\"# amount of runs = {runs}\")\n",
    "\n",
    "print(f\"#   ALL IMPUTATION  :\\t{np.mean(all_means)/const}\\t{np.mean(all_stds)/const}\")\n",
    "print(f\"#   NO IMPUTATION   :\\t{np.mean(no_means)/const}\\t{np.mean(no_stds)/const}\")\n",
    "print(\n",
    "    f\"#   SMART IMPUTATION:\\t{np.mean(smart_means/const)}\\t{np.mean(smart_stds)/const}\"\n",
    ")\n",
    "print(\n",
    "    f\"#   WRONG IMPUTATION:\\t{np.mean(wrong_means/const)}\\t{np.mean(wrong_stds)/const}\"\n",
    ")\n",
    "print(f\"#   ---------------- PEHE_0\")\n",
    "print(\n",
    "    f\"#   ALL IMPUTATION  :\\t{np.mean(all_means_0)/const_0}\\t{np.mean(all_stds_0)/const_0}\"\n",
    ")\n",
    "print(\n",
    "    f\"#   NO IMPUTATION   :\\t{np.mean(no_means_0)/const_0}\\t{np.mean(no_stds_0)/const_0}\"\n",
    ")\n",
    "print(\n",
    "    f\"#   SMART IMPUTATION:\\t{np.mean(smart_means_0)/const_0}\\t{np.mean(smart_stds_0)/const_0}\"\n",
    ")\n",
    "print(\n",
    "    f\"#   WRONG IMPUTATION:\\t{np.mean(wrong_means_0)/const_0}\\t{np.mean(wrong_stds_0)/const_0}\"\n",
    ")\n",
    "print(f\"#   ---------------- PEHE_1\")\n",
    "print(\n",
    "    f\"#   ALL IMPUTATION  :\\t{np.mean(all_means_1)/const_1}\\t{np.mean(all_stds_1)/const_1}\"\n",
    ")\n",
    "print(\n",
    "    f\"#   NO IMPUTATION   :\\t{np.mean(no_means_1)/const_1}\\t{np.mean(no_stds_1)/const_1}\"\n",
    ")\n",
    "print(\n",
    "    f\"#   SMART IMPUTATION:\\t{np.mean(smart_means_1)/const_1}\\t{np.mean(smart_stds_1)/const_1}\"\n",
    ")\n",
    "print(\n",
    "    f\"#   WRONG IMPUTATION:\\t{np.mean(wrong_means_1)/const_1}\\t{np.mean(wrong_stds_1)/const_1}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1900a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP\n",
    "# DATA = twins\n",
    "# learner = T\n",
    "# amount_of_missingness = 0.1\n",
    "# z_d_dim = 24\n",
    "# train size = 5000\n",
    "# amount of runs = 100\n",
    "#   ALL IMPUTATION  :\t0.7572275405984663\t0.10137960558508072\n",
    "#   NO IMPUTATION   :\t0.7393209967553888\t0.295306071041042\n",
    "#   SMART IMPUTATION:\t0.7289547289934614\t0.30209381978963085\n",
    "#   WRONG IMPUTATION:\t0.7591579245817164\t0.0955984508262786\n",
    "#   ---------------- PEHE_0\n",
    "#   ALL IMPUTATION  :\t0.9590341663355869\t0.06496131114974854\n",
    "#   NO IMPUTATION   :\t0.7451106135761542\t0.07975262667674156\n",
    "#   SMART IMPUTATION:\t0.7407708927821102\t0.0768721375689943\n",
    "#   WRONG IMPUTATION:\t0.9570022721829745\t0.06626924375357977\n",
    "#   ---------------- PEHE_1\n",
    "#   ALL IMPUTATION  :\t0.7152607889541894\t0.1098621950516329\n",
    "#   NO IMPUTATION   :\t0.7188177477139469\t0.31928301804139647\n",
    "#   SMART IMPUTATION:\t0.7086193946113668\t0.32730764420330927\n",
    "#   WRONG IMPUTATION:\t0.7175722471726768\t0.10473280009343697\n",
    "\n",
    "\n",
    "# SETUP\n",
    "# DATA = twins\n",
    "# learner = DR\n",
    "# amount_of_missingness = 0.1\n",
    "# z_d_dim = 24\n",
    "# train size = 5000\n",
    "# amount of runs = 100\n",
    "#   ALL IMPUTATION  :\t0.06992683728470135\t0.12223030320868446\n",
    "#   NO IMPUTATION   :\t0.0015434309157597002\t0.003057462629854516\n",
    "#   SMART IMPUTATION:\t0.001306512505831117\t0.01568340567519754\n",
    "#   WRONG IMPUTATION:\t0.1441742963798253\t0.3643103653106824\n",
    "#   ---------------- PEHE_0\n",
    "#   ALL IMPUTATION  :\t0.07927710237670467\t0.11648451860355706\n",
    "#   NO IMPUTATION   :\t0.0026353635492602787\t0.004915892409350565\n",
    "#   SMART IMPUTATION:\t0.002893320158420537\t0.02810305270088261\n",
    "#   WRONG IMPUTATION:\t0.15222514046801144\t0.3761636634413026\n",
    "#   ---------------- PEHE_1\n",
    "#   ALL IMPUTATION  :\t0.06953947911448746\t0.12268835905442628\n",
    "#   NO IMPUTATION   :\t0.0015005056999507465\t0.0029856093072289295\n",
    "#   SMART IMPUTATION:\t0.000083647382212736\t0.0151963668453146\n",
    "#   WRONG IMPUTATION:\t0.14383829666214232\t0.36385829039729634\n",
    "\n",
    "# SETUP\n",
    "# DATA = twins\n",
    "# learner = X\n",
    "# amount_of_missingness = 0.1\n",
    "# z_d_dim = 24\n",
    "# train size = 5000\n",
    "# amount of runs = 100\n",
    "#   ALL IMPUTATION  :\t0.8971831019382526\t0.06530186137937415\n",
    "#   NO IMPUTATION   :\t0.9191404516804176\t0.11422708700128295\n",
    "#   SMART IMPUTATION:\t0.8868597024682495\t0.11941180975316847\n",
    "#   WRONG IMPUTATION:\t0.9067510558077473\t0.06297707246029788\n",
    "#   ---------------- PEHE_0\n",
    "#   ALL IMPUTATION  :\t0.9191401999862722\t0.07143898537490642\n",
    "#   NO IMPUTATION   :\t0.7557023057654503\t0.06678072605997161\n",
    "#   SMART IMPUTATION:\t0.7406099093284292\t0.0643811955837617\n",
    "#   WRONG IMPUTATION:\t0.9139090855281191\t0.06852342110040915\n",
    "#   ---------------- PEHE_1\n",
    "#   ALL IMPUTATION  :\t0.8803944617584534\t0.06673896528555705\n",
    "#   NO IMPUTATION   :\t0.9090887301221944\t0.12087188543240905\n",
    "#   SMART IMPUTATION:\t0.8700209267752238\t0.12665969456825846\n",
    "#   WRONG IMPUTATION:\t0.8810791883919776\t0.0646153150283087"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5b91e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
